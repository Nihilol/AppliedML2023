{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 10:11:58.231544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For a similar Optuna example that demonstrates Keras without a pruner on a regression dataset,\n",
    "see the following link:\n",
    "    https://github.com/optuna/optuna-examples/blob/main/mlflow/keras_mlflow.py\n",
    "\n",
    "\"\"\"\n",
    "import h5py\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,export_graphviz\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from sklearn import tree\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from functions import *\n",
    "import optuna\n",
    "import time\n",
    "import urllib\n",
    "import warnings\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import KerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tempfile\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random\n",
    "r.seed(42)\n",
    "\n",
    "SavePlots = False\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set: (162500, 166)\n",
      "Shape of test data set: (160651, 164)\n",
      "Shape of X: (162500, 160)\n",
      "Shape of y: (162500,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        filename = name.split('/')[1]\n",
    "        return pandas.DataFrame(f[filename][:], dtype=np.float64)\n",
    "\n",
    "train = load_data('data/train')\n",
    "test  = load_data('data/test')\n",
    "\n",
    "print (f'Shape of training data set: {train.shape}')\n",
    "print (f'Shape of test data set: {test.shape}')\n",
    "\n",
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu',\n",
    "                 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0',\n",
    "                 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster',\n",
    "                 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2',\n",
    "                 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3',\n",
    "                 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2',\n",
    "                 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits',\n",
    "                 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG',\n",
    "                 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG',\n",
    "                 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0',\n",
    "                 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3',\n",
    "                 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core',\n",
    "                 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG',\n",
    "                 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG',\n",
    "                 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset',\n",
    "                 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection',\n",
    "                 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1',\n",
    "                 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3',\n",
    "                 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]\n",
    "\n",
    "electron_variable_list = ['actualInteractionsPerCrossing',\n",
    "'averageInteractionsPerCrossing',\n",
    "'correctedActualMu',\n",
    "'correctedAverageMu',\n",
    "'correctedScaledActualMu',\n",
    "'correctedScaledAverageMu',\n",
    "'NvtxReco',\n",
    "'p_nTracks',\n",
    "'p_pt_track',\n",
    "'p_eta',\n",
    "'p_phi',\n",
    "'p_charge',\n",
    "'p_qOverP',\n",
    "'p_z0',\n",
    "'p_d0',\n",
    "'p_sigmad0',\n",
    "'p_d0Sig',\n",
    "'p_EptRatio',\n",
    "'p_dPOverP',\n",
    "'p_z0theta',\n",
    "'p_etaCluster',\n",
    "'p_phiCluster',\n",
    "'p_eCluster',\n",
    "'p_rawEtaCluster',\n",
    "'p_rawPhiCluster',\n",
    "'p_rawECluster',\n",
    "'p_eClusterLr0',\n",
    "'p_eClusterLr1',\n",
    "'p_eClusterLr2',\n",
    "'p_eClusterLr3',\n",
    "'p_etaClusterLr1',\n",
    "'p_etaClusterLr2',\n",
    "'p_phiClusterLr2',\n",
    "'p_eAccCluster',\n",
    "'p_f0Cluster',\n",
    "'p_etaCalo',\n",
    "'p_phiCalo',\n",
    "'p_eTileGap3Cluster',\n",
    "'p_cellIndexCluster',\n",
    "'p_phiModCalo',\n",
    "'p_etaModCalo',\n",
    "'p_dPhiTH3',\n",
    "'p_R12',\n",
    "'p_fTG3',\n",
    "'p_weta2',\n",
    "'p_Reta',\n",
    "'p_Rphi',\n",
    "'p_Eratio',\n",
    "'p_f1',\n",
    "'p_f3',\n",
    "'p_Rhad',\n",
    "'p_Rhad1',\n",
    "'p_deltaEta1',\n",
    "'p_deltaPhiRescaled2',\n",
    "'p_TRTPID',\n",
    "'p_TRTTrackOccupancy',\n",
    "'p_numberOfInnermostPixelHits',\n",
    "'p_numberOfPixelHits',\n",
    "'p_numberOfSCTHits',\n",
    "'p_numberOfTRTHits',\n",
    "'p_numberOfTRTXenonHits',\n",
    "'p_chi2',\n",
    "'p_ndof',\n",
    "'p_SharedMuonTrack',\n",
    "'p_E7x7_Lr2',\n",
    "'p_E7x7_Lr3',\n",
    "'p_E_Lr0_HiG',\n",
    "'p_E_Lr0_LowG',\n",
    "'p_E_Lr0_MedG',\n",
    "'p_E_Lr1_HiG',\n",
    "'p_E_Lr1_LowG',\n",
    "'p_E_Lr1_MedG',\n",
    "'p_E_Lr2_HiG',\n",
    "'p_E_Lr2_LowG',\n",
    "'p_E_Lr2_MedG',\n",
    "'p_E_Lr3_HiG',\n",
    "'p_E_Lr3_LowG',\n",
    "'p_E_Lr3_MedG',\n",
    "'p_ambiguityType',\n",
    "'p_asy1',\n",
    "'p_author',\n",
    "'p_barys1',\n",
    "'p_core57cellsEnergyCorrection',\n",
    "'p_deltaEta0',\n",
    "'p_deltaEta2',\n",
    "'p_deltaEta3',\n",
    "'p_deltaPhi0',\n",
    "'p_deltaPhi1',\n",
    "'p_deltaPhi2',\n",
    "'p_deltaPhi3',\n",
    "'p_deltaPhiFromLastMeasurement',\n",
    "'p_deltaPhiRescaled0',\n",
    "'p_deltaPhiRescaled1',\n",
    "'p_deltaPhiRescaled3',\n",
    "'p_e1152',\n",
    "'p_e132',\n",
    "'p_e235',\n",
    "'p_e255',\n",
    "'p_e2ts1',\n",
    "'p_ecore',\n",
    "'p_emins1',\n",
    "'p_etconeCorrBitset',\n",
    "'p_ethad',\n",
    "'p_ethad1',\n",
    "'p_f1core',\n",
    "'p_f3core',\n",
    "'p_maxEcell_energy',\n",
    "'p_maxEcell_gain',\n",
    "'p_maxEcell_time',\n",
    "'p_maxEcell_x',\n",
    "'p_maxEcell_y',\n",
    "'p_maxEcell_z',\n",
    "'p_nCells_Lr0_HiG',\n",
    "'p_nCells_Lr0_LowG',\n",
    "'p_nCells_Lr0_MedG',\n",
    "'p_nCells_Lr1_HiG',\n",
    "'p_nCells_Lr1_LowG',\n",
    "'p_nCells_Lr1_MedG',\n",
    "'p_nCells_Lr2_HiG',\n",
    "'p_nCells_Lr2_LowG',\n",
    "'p_nCells_Lr2_MedG',\n",
    "'p_nCells_Lr3_HiG',\n",
    "'p_nCells_Lr3_LowG',\n",
    "'p_nCells_Lr3_MedG',\n",
    "'p_pos',\n",
    "'p_pos7',\n",
    "'p_poscs1',\n",
    "'p_poscs2',\n",
    "'p_ptconeCorrBitset',\n",
    "'p_ptconecoreTrackPtrCorrection',\n",
    "'p_r33over37allcalo',\n",
    "'p_topoetconeCorrBitset',\n",
    "'p_topoetconecoreConeEnergyCorrection',\n",
    "'p_topoetconecoreConeSCEnergyCorrection',\n",
    "'p_weta1',\n",
    "'p_widths1',\n",
    "'p_widths2',\n",
    "'p_wtots1',\n",
    "'p_e233',\n",
    "'p_e237',\n",
    "'p_e277',\n",
    "'p_e2tsts1',\n",
    "'p_ehad1',\n",
    "'p_emaxs1',\n",
    "'p_fracs1',\n",
    "'p_DeltaE',\n",
    "'p_E3x5_Lr0',\n",
    "'p_E3x5_Lr1',\n",
    "'p_E3x5_Lr2',\n",
    "'p_E3x5_Lr3',\n",
    "'p_E5x7_Lr0',\n",
    "'p_E5x7_Lr1',\n",
    "'p_E5x7_Lr2',\n",
    "'p_E5x7_Lr3',\n",
    "'p_E7x11_Lr0',\n",
    "'p_E7x11_Lr1',\n",
    "'p_E7x11_Lr2',\n",
    "'p_E7x11_Lr3',\n",
    "'p_E7x7_Lr0',\n",
    "'p_E7x7_Lr1']\n",
    "\n",
    "\n",
    "X = train[electron_variable_list]\n",
    "y = train['Truth']\n",
    "\n",
    "\n",
    "print (f'Shape of X: {X.shape}')\n",
    "print (f'Shape of y: {y.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to set up a simple keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121875, 160) (40625, 160) (121875,) (40625,)\n",
      "Epoch 1/20\n",
      "953/953 [==============================] - 3s 2ms/step - loss: 109.1886 - accuracy: 0.7468 - val_loss: 0.6725 - val_accuracy: 0.7504\n",
      "Epoch 2/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.7037 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 3/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5770 - accuracy: 0.7468 - val_loss: 0.5621 - val_accuracy: 0.7504\n",
      "Epoch 4/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 1.0786 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 5/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 6/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 7/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5665 - accuracy: 0.7468 - val_loss: 0.5621 - val_accuracy: 0.7504\n",
      "Epoch 8/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 9/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5623 - val_accuracy: 0.7504\n",
      "Epoch 10/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5659 - accuracy: 0.7468 - val_loss: 0.5627 - val_accuracy: 0.7504\n",
      "Epoch 11/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 12/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 13/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5659 - accuracy: 0.7468 - val_loss: 0.5622 - val_accuracy: 0.7504\n",
      "Epoch 14/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5619 - val_accuracy: 0.7504\n",
      "Epoch 15/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5622 - val_accuracy: 0.7504\n",
      "Epoch 16/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 17/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5622 - val_accuracy: 0.7504\n",
      "Epoch 18/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5659 - accuracy: 0.7468 - val_loss: 0.5633 - val_accuracy: 0.7504\n",
      "Epoch 19/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5620 - val_accuracy: 0.7504\n",
      "Epoch 20/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5621 - val_accuracy: 0.7504\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147525/3806229351.py:66: UserWarning: Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-05-18 10:13:51,408]\u001b[0m A new study created in memory with name: no-name-b2b4d847-b635-4270-9529-34fb0ff28ada\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:14:28,575]\u001b[0m Trial 0 finished with value: 0.7486276626586914 and parameters: {'n_layers': 2, 'n_units_l0': 11, 'dropout_l0': 0.30019345779655443, 'n_units_l1': 12, 'dropout_l1': 0.38015866025993683, 'learning_rate': 0.007974634959584092}. Best is trial 0 with value: 0.7486276626586914.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:15:17,927]\u001b[0m Trial 1 finished with value: 0.7469538450241089 and parameters: {'n_layers': 2, 'n_units_l0': 126, 'dropout_l0': 0.38467144505358397, 'n_units_l1': 4, 'dropout_l1': 0.41716011127748726, 'learning_rate': 0.0008297526660439818}. Best is trial 0 with value: 0.7486276626586914.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:15:56,577]\u001b[0m Trial 2 finished with value: 0.7461415529251099 and parameters: {'n_layers': 2, 'n_units_l0': 8, 'dropout_l0': 0.35306113994308774, 'n_units_l1': 43, 'dropout_l1': 0.20992703891518738, 'learning_rate': 0.026644903245149884}. Best is trial 0 with value: 0.7486276626586914.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:16:36,652]\u001b[0m Trial 3 finished with value: 0.7476430535316467 and parameters: {'n_layers': 3, 'n_units_l0': 11, 'dropout_l0': 0.30152725078466586, 'n_units_l1': 5, 'dropout_l1': 0.45369049299165776, 'n_units_l2': 20, 'dropout_l2': 0.25737448157377574, 'learning_rate': 0.0023204811292092025}. Best is trial 0 with value: 0.7486276626586914.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:17:12,144]\u001b[0m Trial 4 finished with value: 0.7444676756858826 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_l0': 0.3953217563350306, 'learning_rate': 0.008695229978862493}. Best is trial 0 with value: 0.7486276626586914.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:17:46,320]\u001b[0m Trial 5 finished with value: 0.7514338493347168 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.3363316643233793, 'learning_rate': 0.002041892163938829}. Best is trial 5 with value: 0.7514338493347168.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:18:23,855]\u001b[0m Trial 6 finished with value: 0.7499569058418274 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_l0': 0.22273959664174853, 'n_units_l1': 14, 'dropout_l1': 0.4785111157231998, 'learning_rate': 0.0024720492832045783}. Best is trial 5 with value: 0.7514338493347168.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:07,852]\u001b[0m Trial 7 finished with value: 0.7482338547706604 and parameters: {'n_layers': 2, 'n_units_l0': 58, 'dropout_l0': 0.347327981356808, 'n_units_l1': 49, 'dropout_l1': 0.28907575322333645, 'learning_rate': 0.001489264850693693}. Best is trial 5 with value: 0.7514338493347168.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:44,270]\u001b[0m Trial 8 finished with value: 0.7497353553771973 and parameters: {'n_layers': 2, 'n_units_l0': 9, 'dropout_l0': 0.2397921558762621, 'n_units_l1': 4, 'dropout_l1': 0.36366879391003626, 'learning_rate': 0.023909469631868345}. Best is trial 5 with value: 0.7514338493347168.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:47,907]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:50,678]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:53,449]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:56,244]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:19:59,823]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:20:02,538]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:20:05,224]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:20:09,014]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:20:48,445]\u001b[0m Trial 17 finished with value: 0.7518523335456848 and parameters: {'n_layers': 2, 'n_units_l0': 27, 'dropout_l0': 0.2989362088208226, 'n_units_l1': 10, 'dropout_l1': 0.33703722671583203, 'learning_rate': 9.799982345738969e-05}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:20:51,557]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:20:54,548]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:21:35,300]\u001b[0m Trial 20 finished with value: 0.7490215301513672 and parameters: {'n_layers': 3, 'n_units_l0': 17, 'dropout_l0': 0.32442048741928137, 'n_units_l1': 27, 'dropout_l1': 0.31941618902903185, 'n_units_l2': 4, 'dropout_l2': 0.45947770080713046, 'learning_rate': 0.0001394037535221576}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:21:38,625]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:21:41,932]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:21:45,152]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:21:48,184]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:21:51,116]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:22:28,051]\u001b[0m Trial 26 finished with value: 0.7492676973342896 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_l0': 0.23564656833025496, 'n_units_l1': 8, 'dropout_l1': 0.35120428199069986, 'learning_rate': 0.0010117194098200307}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:23:11,360]\u001b[0m Trial 27 finished with value: 0.7491446137428284 and parameters: {'n_layers': 3, 'n_units_l0': 23, 'dropout_l0': 0.290900784705588, 'n_units_l1': 23, 'dropout_l1': 0.4477584876209762, 'n_units_l2': 29, 'dropout_l2': 0.38220747185580756, 'learning_rate': 0.002755292068682085}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:23:14,292]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:23:51,680]\u001b[0m Trial 29 finished with value: 0.7502769231796265 and parameters: {'n_layers': 2, 'n_units_l0': 11, 'dropout_l0': 0.3066780015736906, 'n_units_l1': 15, 'dropout_l1': 0.267853691630762, 'learning_rate': 0.006217681603277705}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:23:54,664]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:23:57,720]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:24:00,753]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:24:39,420]\u001b[0m Trial 33 finished with value: 0.7494646310806274 and parameters: {'n_layers': 2, 'n_units_l0': 13, 'dropout_l0': 0.33534349967132043, 'n_units_l1': 18, 'dropout_l1': 0.33483918101565036, 'learning_rate': 0.0011569228399369502}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:24:42,480]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:24:45,603]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:24:48,904]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:24:51,923]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:25:29,103]\u001b[0m Trial 38 finished with value: 0.7495138645172119 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'dropout_l0': 0.33742618682639536, 'n_units_l1': 14, 'dropout_l1': 0.24780995972059208, 'learning_rate': 0.0012999039487951042}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:26:03,485]\u001b[0m Trial 39 finished with value: 0.7492676973342896 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_l0': 0.3716413115839593, 'learning_rate': 0.014450535020687237}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:26:47,134]\u001b[0m Trial 40 finished with value: 0.7495877146720886 and parameters: {'n_layers': 3, 'n_units_l0': 14, 'dropout_l0': 0.22543242454316725, 'n_units_l1': 11, 'dropout_l1': 0.3816876326410174, 'n_units_l2': 53, 'dropout_l2': 0.4098442718940431, 'learning_rate': 0.002105443881344261}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:26:50,147]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:26:53,170]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:26:56,138]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:26:58,886]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:27:01,905]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:27:38,716]\u001b[0m Trial 46 finished with value: 0.7493415474891663 and parameters: {'n_layers': 2, 'n_units_l0': 14, 'dropout_l0': 0.23141074470203604, 'n_units_l1': 5, 'dropout_l1': 0.20448515821760668, 'learning_rate': 0.0017129936690868516}. Best is trial 17 with value: 0.7518523335456848.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:27:41,745]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:27:45,028]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "/tmp/ipykernel_147525/3806229351.py:54: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna.integration.TFKerasPruningCallback`\n",
      "  callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
      "\u001b[32m[I 2023-05-18 10:27:47,759]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  50\n",
      "  Number of pruned trials:  31\n",
      "  Number of complete trials:  19\n",
      "Best trial:\n",
      "  Value:  0.7518523335456848\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 27\n",
      "    dropout_l0: 0.2989362088208226\n",
      "    n_units_l1: 10\n",
      "    dropout_l1: 0.33703722671583203\n",
      "    learning_rate: 9.799982345738969e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 1\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True)\n",
    "        model.add(Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Clear clutter from previous session graphs.\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    logdir = tempfile.mkdtemp()\n",
    "    \n",
    "    # callback_list = [\n",
    "    #             tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    #             tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    # ]\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCHSIZE,\n",
    "        callbacks=[KerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "optimise_keras = False\n",
    "\n",
    "if optimise_keras:\n",
    "    warnings.warn(\n",
    "        \"Recent Keras release (2.4.0) simply redirects all APIs \"\n",
    "        \"in the standalone keras package to point to tf.keras. \"\n",
    "        \"There is now only one Keras: tf.keras. \"\n",
    "        \"There may be some breaking changes for some workflows by upgrading to keras 2.4.0. \"\n",
    "        \"Test before upgrading. \"\n",
    "        \"REF: https://github.com/keras-team/keras/releases/tag/2.4.0. \"\n",
    "        \"There is an alternative callback function that can be used instead: \"\n",
    "        \":class:`~optuna.integration.TFKerasPruningCallback`\",\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the permutation importance of all the various parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = KerasRegressor(build_fn=base_model, **sk_params)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the actual model from the optimal hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121875, 160) (40625, 160) (121875,) (40625,)\n",
      "Epoch 1/20\n",
      "953/953 [==============================] - 3s 2ms/step - loss: 4188.1606 - accuracy: 0.7465 - val_loss: 25.4228 - val_accuracy: 0.7512\n",
      "Epoch 2/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 127.4667 - accuracy: 0.7465 - val_loss: 4.7600 - val_accuracy: 0.7512\n",
      "Epoch 3/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 100.9936 - accuracy: 0.7465 - val_loss: 3.3328 - val_accuracy: 0.7512\n",
      "Epoch 4/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 119.7741 - accuracy: 0.7465 - val_loss: 1.8012 - val_accuracy: 0.7512\n",
      "Epoch 5/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 64.9724 - accuracy: 0.7465 - val_loss: 1.0134 - val_accuracy: 0.7512\n",
      "Epoch 6/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 60.3685 - accuracy: 0.7465 - val_loss: 0.8626 - val_accuracy: 0.7512\n",
      "Epoch 7/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 34.0317 - accuracy: 0.7465 - val_loss: 0.7906 - val_accuracy: 0.7512\n",
      "Epoch 8/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 40.5039 - accuracy: 0.7465 - val_loss: 0.7649 - val_accuracy: 0.7512\n",
      "Epoch 9/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 47.3955 - accuracy: 0.7465 - val_loss: 0.7150 - val_accuracy: 0.7512\n",
      "Epoch 10/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 9.7184 - accuracy: 0.7465 - val_loss: 0.6803 - val_accuracy: 0.7512\n",
      "Epoch 11/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 63.0344 - accuracy: 0.7465 - val_loss: 0.6523 - val_accuracy: 0.7512\n",
      "Epoch 12/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 3.1676 - accuracy: 0.7465 - val_loss: 0.6303 - val_accuracy: 0.7512\n",
      "Epoch 13/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 5.1457 - accuracy: 0.7465 - val_loss: 0.6120 - val_accuracy: 0.7512\n",
      "Epoch 14/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 4.7737 - accuracy: 0.7465 - val_loss: 0.6052 - val_accuracy: 0.7512\n",
      "Epoch 15/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 2.8140 - accuracy: 0.7465 - val_loss: 0.5855 - val_accuracy: 0.7512\n",
      "Epoch 16/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 91.1266 - accuracy: 0.7465 - val_loss: 0.5748 - val_accuracy: 0.7512\n",
      "Epoch 17/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 35.6071 - accuracy: 0.7465 - val_loss: 0.5680 - val_accuracy: 0.7512\n",
      "Epoch 18/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 3.4985 - accuracy: 0.7465 - val_loss: 0.5600 - val_accuracy: 0.7512\n",
      "Epoch 19/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 33.3773 - accuracy: 0.7465 - val_loss: 0.5600 - val_accuracy: 0.7512\n",
      "Epoch 20/20\n",
      "953/953 [==============================] - 2s 2ms/step - loss: 8.6063 - accuracy: 0.7465 - val_loss: 0.5600 - val_accuracy: 0.7512\n"
     ]
    }
   ],
   "source": [
    "BATCHSIZE = 128\n",
    "CLASSES = 1\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers =  2\n",
    "    n_units_l0 = 27\n",
    "    dropout_l0 =  0.2989362088208226\n",
    "    n_units_l1 =  10\n",
    "    dropout_l1 =  0.33703722671583203\n",
    "    learning_rate =  9.799982345738969e-05\n",
    "    model = Sequential()\n",
    "    model.add(Dense(activation=\"relu\", units=n_units_l0))\n",
    "    model.add(Dropout(rate = dropout_l0))\n",
    "    model.add(Dense(activation=\"relu\", units=n_units_l1))\n",
    "    model.add(Dropout(rate = dropout_l1))\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Clear clutter from previous session graphs.\n",
    "keras.backend.clear_session()\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print(x_train.shape, x_valid.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "    # Generate our trial model.\n",
    "model = create_model()\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCHSIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
